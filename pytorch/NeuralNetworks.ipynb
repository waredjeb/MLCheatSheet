{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks with PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import necessary modules\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's load a dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#Define a transformation to normalize the data\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "#Download and load dataset with torchvision\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# We can loop over images using an iterator\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f27d6792ac8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap = 'Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to build a multi layer network. The images are 28x28 2D tensors, we need so to convert them into 1D vectors. We need to convert the batch of images with shape (64,1,28,28) to have shape of (64,784), this operation is called flattening, we flattened the 2D images into 1D vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = images.view(images.shape[0], -1)\n",
    "#Note that the -1 means 'flattening the others dimensions'\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Let's build our network!\n",
    "#Starting with the activation function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + torch.exp(-x))\n",
    "\n",
    "#Create parameters!\n",
    "nodes = 256\n",
    "w1 = torch.randn(inputs.shape[1], nodes)\n",
    "b1 = torch.randn(nodes)\n",
    "\n",
    "#we want output to have dimension 10 as the number of digits\n",
    "\n",
    "w2 = torch.randn(w1.shape[1], 10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = sigmoid((torch.mm(inputs,w1)) + b1)\n",
    "\n",
    "output = torch.mm(h, w2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim = 1).view(-1,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "probabilities = softmax(output)\n",
    "print(probabilities.shape)\n",
    "# probabilities\n",
    "#check if they are correct, the sum must return 1\n",
    "print(probabilities.sum(dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building networks with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch provides a module nn that makes building networks simpler\n",
    "\n",
    "#subclassing nn.Module\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        #MANDATORY\n",
    "        super().__init__() #allows inheritance of nn.Module\n",
    "        \n",
    "        #beginning layer\n",
    "        #defines weights and bias automatically\n",
    "        self.hidden = torch.nn.Linear(784, 256)\n",
    "        #output layer\n",
    "        self.output = torch.nn.Linear(256, 10)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.softmax = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More concisely through torch.nn.functional\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = torch.nn.Linear(784, 256)\n",
    "        \n",
    "        self.output = torch,nn.Linear(256,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        \n",
    "        x = F.softmax(self.output(x), dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More concisely through torch.nn.functional\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.h1 = torch.nn.Linear(784, 256)\n",
    "        \n",
    "        self.h2 = torch.nn.Linear(256, 64)\n",
    "        \n",
    "        self.output = torch,nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.h1(x)) #different activation function\n",
    "        \n",
    "        x = F.relu(self.h2(x))\n",
    "        \n",
    "        x = F.softmax(self.output(h2), dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3053, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear(inputs.shape[1], 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "logits = model(inputs)\n",
    "\n",
    "loss = criterion(logits, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2957, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear(inputs.shape[1], 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10),\n",
    "                      nn.LogSoftmax(dim = 1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "logprob = model(inputs)\n",
    "\n",
    "loss = criterion(logprob, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's understand how we can compute the gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3519, -0.1708],\n",
      "        [-0.0276,  0.4501]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad = True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1238, 0.0292],\n",
      "        [0.0008, 0.2026]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x **2 \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7f27c8861550>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0891, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y.mean()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the gradient we need to run the ```.backward ``` method on a variable ``` z ```. This will calculate the gradient for ``` z ``` with respect to ``` x ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1759, -0.0854],\n",
      "        [-0.0138,  0.2250]])\n",
      "tensor([[ 0.1759, -0.0854],\n",
      "        [-0.0138,  0.2250]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Autograd together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3266, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear(inputs.shape[1], 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10),\n",
    "                      nn.LogSoftmax(dim = 1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "logprob = model(inputs)\n",
    "\n",
    "loss = criterion(logprob, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before bacward pass:\n",
      " None\n",
      "After bacward pass:\n",
      " tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0038,  0.0038,  0.0038,  ...,  0.0038,  0.0038,  0.0038],\n",
      "        [-0.0010, -0.0010, -0.0010,  ..., -0.0010, -0.0010, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0026,  0.0026,  0.0026,  ...,  0.0026,  0.0026,  0.0026],\n",
      "        [-0.0013, -0.0013, -0.0013,  ..., -0.0013, -0.0013, -0.0013],\n",
      "        [ 0.0030,  0.0030,  0.0030,  ...,  0.0030,  0.0030,  0.0030]])\n"
     ]
    }
   ],
   "source": [
    "print('Before bacward pass:\\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After bacward pass:\\n', model[0].weight.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we have all the tools to train a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "#To update the wights!\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient -  tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0110,  0.0110,  0.0110,  ...,  0.0110,  0.0110,  0.0110],\n",
      "        [-0.0029, -0.0029, -0.0029,  ..., -0.0029, -0.0029, -0.0029],\n",
      "        ...,\n",
      "        [ 0.0075,  0.0075,  0.0075,  ...,  0.0075,  0.0075,  0.0075],\n",
      "        [-0.0031, -0.0031, -0.0031,  ..., -0.0031, -0.0031, -0.0031],\n",
      "        [ 0.0092,  0.0092,  0.0092,  ...,  0.0092,  0.0092,  0.0092]])\n"
     ]
    }
   ],
   "source": [
    "output = model.forward(inputs)\n",
    "\n",
    "loss = criterion(output, labels)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('Gradient - ', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[-0.0090, -0.0249, -0.0165,  ...,  0.0285,  0.0316, -0.0131],\n",
      "        [ 0.0098,  0.0195,  0.0341,  ..., -0.0348,  0.0235, -0.0136],\n",
      "        [ 0.0136,  0.0049, -0.0279,  ...,  0.0127,  0.0060, -0.0144],\n",
      "        ...,\n",
      "        [-0.0082,  0.0175, -0.0299,  ...,  0.0108,  0.0065, -0.0111],\n",
      "        [-0.0277,  0.0337,  0.0303,  ...,  0.0153, -0.0189,  0.0118],\n",
      "        [-0.0302,  0.0226, -0.0316,  ..., -0.0046, -0.0257, -0.0223]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = w - 0.01*model[0].weight.grad # Step done by optimizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = difference - model[0].weight\n",
    "#Indeed, the difference is zero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient -  Parameter containing:\n",
      "tensor([[-0.0090, -0.0249, -0.0165,  ...,  0.0285,  0.0316, -0.0131],\n",
      "        [ 0.0093,  0.0190,  0.0337,  ..., -0.0352,  0.0230, -0.0140],\n",
      "        [ 0.0136,  0.0049, -0.0279,  ...,  0.0127,  0.0060, -0.0144],\n",
      "        ...,\n",
      "        [-0.0082,  0.0175, -0.0299,  ...,  0.0108,  0.0065, -0.0110],\n",
      "        [-0.0279,  0.0335,  0.0301,  ...,  0.0151, -0.0191,  0.0116],\n",
      "        [-0.0306,  0.0222, -0.0320,  ..., -0.0050, -0.0261, -0.0227]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Clear the gradients, do this because gadients are accumulated!!!\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "output = model.forward(inputs)\n",
    "\n",
    "loss = criterion(output, labels)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('Gradient - ', model[0].weight)\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Training loss 1.8576685570196303\n",
      "1\n",
      "Training loss 0.793737343633607\n",
      "2\n",
      "Training loss 0.5083702960565909\n",
      "3\n",
      "Training loss 0.42508536975965827\n",
      "4\n",
      "Training loss 0.38547872114918635\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(nn.Linear(inputs.shape[1], 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10),\n",
    "                      nn.LogSoftmax(dim = 1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.003)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    print(e)\n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    else:\n",
    "        print(f\"Training loss {running_loss/len(trainloader)}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'helper' has no attribute 'view_classify'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-74dc29805497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'helper' has no attribute 'view_classify'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import helpML\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "    \n",
    "ps = F.softmax(logits, dim = 1)\n",
    "helper.view_classify(img.view(1,28,28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpML.py  MNIST_data  __pycache__  PyTorch_Introduction.ipynb\tUntitled.ipynb\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
